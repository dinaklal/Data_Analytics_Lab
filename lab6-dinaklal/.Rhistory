# # # # # # # # # # # #
# PageRank Algorithm  #
# # # # # # # # # # # # '
# Define function to load an adjacency matrix
A_load <- function (f) {
}
# Define function to generate an adjacency matrix
A_gen <- function (n, p) {
A <- matrix(sample(0:1, n*n, prob = c(1-p, p), replace = T), ncol = n, byrow = T)
cat(paste('The generated graph has', nrow(A), 'vertices and', sum(A), 'edges.'))
return(A)
}
# Define PageRank function (p = probability of teleport)
PageRank <- function (A, p, output = T) {
# Define assertions
if (!is.matrix(A) | !all(A %in% 0:1)) {
stop(noquote('no (valid) adjacency matrix is provided.'))
} else if (!is.numeric(p) | p < 0 | p > 1) {
stop(noquote('p must be a probability between 0 and 1.'))
}
# Initialize transition matrix
s <- matrix(rep(NA, ncol(A)), ncol = ncol(A))
s[1, ] <- rep(1/ncol(A), ncol(A))
i <- 1
# Repeat Markov Chain until convergence
while (T) {
# Calculate transition vector at t + 1
t <- rep(NA, ncol(A))
for (j in 1:ncol(A)) {
t[j] <- ifelse(sum(A[j, ]) == 0
, 1 / ncol(A)
, p / ncol(A) + (1 - p) * sum(A[, j] * (s[i, ] / apply(A, 1, sum))))
}
s <- rbind(s, t)
i <- i + 1
# Break if converged
if (i > 1) if (all(round(s[i - 1, ], 4) == round(s[i, ], 4))) break
}
# Build and return output
rank <- data.frame(as.character(1:ncol(s)), round(s[i, ], 4), rep(p, ncol(A)))
colnames(rank) <- c('Node', 'PageRank', 'P')
if (output) {
cat(noquote('PageRank Output:\n\n'))
print(rank[order(-rank$PageRank), c('Node', 'PageRank')], row.names = F)
cat(noquote(paste('\nPageRank converged in', i, 'iterations.')))
} else {
return(rank[order(-rank$PageRank), ])
}
}
# Load/generate an adjacency matrix
A <- A_gen(10, .6)
# Plot the graph
library(igraph)
plot(graph.adjacency(A,'directed'))
# Do PageRank on example graph with P(teleport) = 0.2
PageRank(A, .2)
# Effect of P(teleport) on ranking
library(ggplot2)
# Calculate permutations
df <- data.frame()
for (i in seq(0,1,.005)) {
df <- rbind(df, PageRank(A, i, 100))
}
# Plot
ggplot(data=df, aes(x=i, y=PageRank(df,.2,100))) +
geom_line(size=1) +
scale_x_continuous(breaks = seq(0,1,0.1)) +
expand_limits(y=0.135) +
xlab('P(teleport)') +
ggtitle('Effect of P(teleport) on PageRank')
# # # # # # # # # # # #
# PageRank Algorithm  #
# # # # # # # # # # # # '
# Define function to load an adjacency matrix
A_load <- function (f) {
A <- as.matrix(read.table(f))
cat(paste('The loaded graph has', nrow(A), 'vertices and', sum(A), 'edges.'))
return(A)
}
# Define function to generate an adjacency matrix
A_gen <- function (n, p) {
A <- matrix(sample(0:1, n*n, prob = c(1-p, p), replace = T), ncol = n, byrow = T)
cat(paste('The generated graph has', nrow(A), 'vertices and', sum(A), 'edges.'))
return(A)
}
# Define PageRank function (p = probability of teleport)
PageRank <- function (A, p, output = T) {
# Define assertions
if (!is.matrix(A) | !all(A %in% 0:1)) {
stop(noquote('no (valid) adjacency matrix is provided.'))
} else if (!is.numeric(p) | p < 0 | p > 1) {
stop(noquote('p must be a probability between 0 and 1.'))
}
# Initialize transition matrix
s <- matrix(rep(NA, ncol(A)), ncol = ncol(A))
s[1, ] <- rep(1/ncol(A), ncol(A))
i <- 1
# Repeat Markov Chain until convergence
while (T) {
# Calculate transition vector at t + 1
t <- rep(NA, ncol(A))
for (j in 1:ncol(A)) {
t[j] <- ifelse(sum(A[j, ]) == 0
, 1 / ncol(A)
, p / ncol(A) + (1 - p) * sum(A[, j] * (s[i, ] / apply(A, 1, sum))))
}
s <- rbind(s, t)
i <- i + 1
# Break if converged
if (i > 1) if (all(round(s[i - 1, ], 4) == round(s[i, ], 4))) break
}
# Build and return output
rank <- data.frame(as.character(1:ncol(s)), round(s[i, ], 4), rep(p, ncol(A)))
colnames(rank) <- c('Node', 'PageRank', 'P')
if (output) {
cat(noquote('PageRank Output:\n\n'))
print(rank[order(-rank$PageRank), c('Node', 'PageRank')], row.names = F)
cat(noquote(paste('\nPageRank converged in', i, 'iterations.')))
} else {
return(rank[order(-rank$PageRank), ])
}
}
# Load/generate an adjacency matrix
A <- A_load('../A_big.txt')
A <- A_gen(10, .6)
# Plot the graph
library(igraph)
plot(graph.adjacency(A,'directed'))
# Do PageRank on example graph with P(teleport) = 0.2
PageRank(A, .2)
# Effect of P(teleport) on ranking
library(ggplot2)
# Calculate permutations
df <- data.frame()
for (i in seq(0,1,.005)) {
df <- rbind(df, PageRank(A, i, 100, F))
}
# Plot
ggplot(data=df, aes(x=P, y=PageRank, group=Node, fill=Node, colour=Node)) +
geom_line(size=1) +
scale_x_continuous(breaks = seq(0,1,0.1)) +
expand_limits(y=0.135) +
xlab('P(teleport)') +
ggtitle('Effect of P(teleport) on PageRank')
# # # # # # # # # # # #
# PageRank Algorithm  #
# # # # # # # # # # # # '
# Define function to load an adjacency matrix
A_load <- function (f) {
}
# Define function to generate an adjacency matrix
A_gen <- function (n, p) {
A <- matrix(sample(0:1, n*n, prob = c(1-p, p), replace = T), ncol = n, byrow = T)
cat(paste('The generated graph has', nrow(A), 'vertices and', sum(A), 'edges.'))
return(A)
}
# Define PageRank function (p = probability of teleport)
PageRank <- function (A, p, output = T) {
# Define assertions
if (!is.matrix(A) | !all(A %in% 0:1)) {
stop(noquote('no (valid) adjacency matrix is provided.'))
} else if (!is.numeric(p) | p < 0 | p > 1) {
stop(noquote('p must be a probability between 0 and 1.'))
}
# Initialize transition matrix
s <- matrix(rep(NA, ncol(A)), ncol = ncol(A))
s[1, ] <- rep(1/ncol(A), ncol(A))
i <- 1
# Repeat Markov Chain until convergence
while (T) {
# Calculate transition vector at t + 1
t <- rep(NA, ncol(A))
for (j in 1:ncol(A)) {
t[j] <- ifelse(sum(A[j, ]) == 0
, 1 / ncol(A)
, p / ncol(A) + (1 - p) * sum(A[, j] * (s[i, ] / apply(A, 1, sum))))
}
s <- rbind(s, t)
i <- i + 1
# Break if converged
if (i > 1) if (all(round(s[i - 1, ], 4) == round(s[i, ], 4))) break
}
# Build and return output
rank <- data.frame(as.character(1:ncol(s)), round(s[i, ], 4), rep(p, ncol(A)))
colnames(rank) <- c('Node', 'PageRank', 'P')
if (output) {
cat(noquote('PageRank Output:\n\n'))
print(rank[order(-rank$PageRank), c('Node', 'PageRank')], row.names = F)
cat(noquote(paste('\nPageRank converged in', i, 'iterations.')))
} else {
return(rank[order(-rank$PageRank), ])
}
}
# Load/generate an adjacency matrix
A <- A_gen(10, .6)
# Plot the graph
library(igraph)
plot(graph.adjacency(A,'directed'))
# Do PageRank on example graph with P(teleport) = 0.2
PageRank(A, .2)
# Effect of P(teleport) on ranking
library(ggplot2)
# Calculate permutations
df <- data.frame()
for (i in seq(0,1,.005)) {
df <- rbind(df, PageRank(A, i, 100))
}
setwd("~/mtech/sem3/Data Analytics LAB/Labs/lab7-dinaklal")
library(arules)
library(arulesViz)
library(RColorBrewer)
# import dataset
data("Groceries")
# using apriori() function
rules <- apriori(Groceries,
parameter = list(supp = 0.01, conf = 0.2))
# using inspect() function to get the 10 min Association rule
inspect(rules[1:10])
# using itemFrequencyPlot() function
arules::itemFrequencyPlot(Groceries, topN = 20,
col = brewer.pal(8, 'Pastel2'),
main = 'Relative Item Frequency Plot',
type = "relative",
ylab = "Item Frequency (Relative)")
# 20 % Support and 50% Confidence
rules <- apriori(Groceries,
parameter = list(supp = 0.2, conf = 0.5))
# using inspect() function to get the 10 min Association rule
inspect(rules)
rules
# using itemFrequencyPlot() function
arules::itemFrequencyPlot(Groceries, topN = 20,
col = brewer.pal(8, 'Pastel2'),
main = 'Relative Item Frequency Plot',
type = "relative",
ylab = "Item Frequency (Relative)")
setwd("~/mtech/sem3/Data Analytics LAB/Labs/lab6-dinaklal")
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
df <- USArrests
df
#remove blank fields
df <- na.omit(df)
df
#normalise
df <- scale(df)
#Best k
set.seed(123)
# function to compute total within-cluster sum of square
wss <- function(k) {
kmeans(df, k, nstart = 10 )$tot.withinss
}
# Compute and plot wss for k = 1 to k = 15
k.values <- 1:15
# extract wss for 2-15 clusters
library(purrr)
wss_values <- map_dbl(k.values, wss)
plot(k.values, wss_values,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
install.packages("factoextra")
library(factoextra)
#distance <- get_dist(df)
#distance
#fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
#k2 <- kmeans(df, centers = 2, nstart = 25)
#str(k2)
#fviz_cluster(k2, data = df)
#Giving different clusters
#k3 <- kmeans(df, centers = 3, nstart = 25)
k4 <- kmeans(df, centers = 4, nstart = 25)
str(k4)
#k5 <- kmeans(df, centers = 5, nstart = 25)
# plots to compare
#p1 <- fviz_cluster(k2, geom = "point", data = df) + ggtitle("k = 2")
#p2 <- fviz_cluster(k3, geom = "point",  data = df) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = df) + ggtitle("k = 4")
#p4 <- fviz_cluster(k5, geom = "point",  data = df) + ggtitle("k = 5")
p3
#library(gridExtra)
#grid.arrange(p1, p2, p3, p4, nrow = 2)
##.....................Manhattan...................
set.seed(123)
wss <- function(k) {
kmeans(df, k, nstart = 10 )$tot.withinss
}
k.values <- 1:15
library(purrr)
wss_values <- map_dbl(k.values, wss)
plot(k.values, wss_values,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
k4 <- kmeans(df, centers = 4, nstart = 25,method="manhattan")
str(k4)
library(cluster)
p3 <- fviz_cluster(k4, geom = "point",  data = df) + ggtitle("k = 4")
p3
install.packages("factoextra")
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
df <- USArrests
df
#remove blank fields
df <- na.omit(df)
df
#normalise
df <- scale(df)
#Best k
set.seed(123)
# function to compute total within-cluster sum of square
wss <- function(k) {
kmeans(df, k, nstart = 10 )$tot.withinss
}
# Compute and plot wss for k = 1 to k = 15
k.values <- 1:15
# extract wss for 2-15 clusters
library(purrr)
wss_values <- map_dbl(k.values, wss)
plot(k.values, wss_values,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
install.packages("factoextra")
library(factoextra)
#distance <- get_dist(df)
#distance
#fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
#k2 <- kmeans(df, centers = 2, nstart = 25)
#str(k2)
#fviz_cluster(k2, data = df)
#Giving different clusters
#k3 <- kmeans(df, centers = 3, nstart = 25)
k4 <- kmeans(df, centers = 4, nstart = 25)
str(k4)
#k5 <- kmeans(df, centers = 5, nstart = 25)
# plots to compare
#p1 <- fviz_cluster(k2, geom = "point", data = df) + ggtitle("k = 2")
#p2 <- fviz_cluster(k3, geom = "point",  data = df) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = df) + ggtitle("k = 4")
#p4 <- fviz_cluster(k5, geom = "point",  data = df) + ggtitle("k = 5")
p3
#library(gridExtra)
#grid.arrange(p1, p2, p3, p4, nrow = 2)
##.....................Manhattan...................
set.seed(123)
wss <- function(k) {
kmeans(df, k, nstart = 10 )$tot.withinss
}
k.values <- 1:15
library(purrr)
wss_values <- map_dbl(k.values, wss)
plot(k.values, wss_values,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
k4 <- kmeans(df, centers = 4, nstart = 25,method="manhattan")
str(k4)
library(cluster)
p3 <- fviz_cluster(k4, geom = "point",  data = df) + ggtitle("k = 4")
p3
install.packages("factoextra")
